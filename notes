08/15

Installing k8s

kubeadm init fails

$ sudo kubeadm init
[sudo] password for cloud_user:
[init] Using Kubernetes version: v1.24.3
[preflight] Running pre-flight checks
error execution phase preflight: [preflight] Some fatal errors occurred:
        [ERROR CRI]: container runtime is not running: output: E0815
        21:48:51.858012    4642 remote_runtime.go:925] "Status from runtime
        service failed" err="rpc error: code = Unimplemented desc = unknown
        service runtime.v1alpha2.RuntimeService"
        time="2022-08-15T21:48:51Z" level=fatal msg="getting status of runtime:
        rpc error: code = Unimplemented desc = unknown service
        runtime.v1alpha2.RuntimeService"
        , error: exit status 1
Workaround* (doesn't work)
* https://stackoverflow.com/questions/72504257/i-encountered-when-executing-kubeadm-init-error-issue
* https://github.com/containerd/containerd/issues/4581

NEXT:
Go through the installation docs:
https://kubernetes.io/docs/setup/
https://kubernetes.io/docs/setup/production-environment/container-runtimes/#install-and-configure-prerequisites
install test cluster on la
install minikube
install hub on kube with synopsysctl / helm

08/16
TEST TOOLS:

Kind installed and running fine
Installing Hub with Helm3
$ helm repo add synopsys https://sig-repo.synopsys.com/artifactory/sig-cloudnative

$ BD_NAME="bd"
$ kubectl create ns ${BD_NAME}
BD_SIZE="sizes-gen03/10sph"

cd /opt/blackduck/hub-2022.7.0/kubernetes/blackduck
helm install --help
Usage:
  helm install [NAME] [CHART] [flags]

$ helm install ${BD_NAME} synopsys/blackduck --namespace ${BD_NAME} -f ${BD_SIZE}.yaml --set tlsCertSecretName=${BD_NAME}-blackduck-webserver-certificate

Error: INSTALLATION FAILED: failed pre-install: unable to build kubernetes
object for pre-install hook blackduck/templates/postgres-config.yaml: error validating "": error validating data: unknown object type "nil" in ConfigMap.data.HUB_POSTGRES_HOST

08/17
test with helm2

https://github.com/helm/helm/issues/5100#issuecomment-533787541
deleted cluster, starting from scratch

# creat cluster with kind

same error: 
 helm install ${BD_NAME} synopsys/blackduck --namespace ${BD_NAME} -f
 ${BD_SIZE}.yaml --set
 tlsCertSecretName=${BD_NAME}-blackduck-webserver-certificate
 Error: INSTALLATION FAILED: failed pre-install: unable to build kubernetes
 object for pre-install hook blackduck/templates/postgres-config.yaml: error
 validating "": error validating data: unknown object type "nil" in
 ConfigMap.data.HUB_POSTGRES_HOST
 
08/19

* fix Github config
* fixed apt google repo config

08/20

* add ssh keys to the Ubuntu nodes
ssh-keygen
ssh-copy-id -i $K8S_KEY_NAME $K8S_NODE

* fix Ubuntu script(correct Google repo)
* run script on multiple nodes
 1/ Install pssh
 sudo yum install -y pssh
 2/ Create hosts file
 vi ~/.pssh_hosts
 Contents
 [user@]host[:port]
 3/ Test
 pssh -h ~/.pssh_hosts -i "hostname"

* set no sudo passwd
  with NOPASSWD:ALL still promts for password
  https://unix.stackexchange.com/questions/666207/setting-nopasswd-for-a-user-still-promts-for-a-password

NEXT: 
  
08/21 

* fix nopasswd sudo
  1/ check user sudo permissions
  sudo -l -U cloud_user
  2/ Edit cloud_user sudo config:
  sudo visudo -f /etc/sudoers.d/90-cloud-init-users

* run install script with pssh
  pssh -h ~/.pssh_hosts -o ~/pssh-logs "bash $SCRIPTNAME"
  
  [FAILURE] Timed out, Killed by signal 9
  pssh command will only last 60 seconds if you not input -t option.

  pssh -t 3600 -h ~/.pssh_hosts -o ~/pssh-logs "bash 2_configure_nodes_ubuntu.sh"

* initialize cluster
  1/ On a control plane node 

sudo kubeadm init --pod-network-cidr 192.168.0.0/16 --kubernetes-version 1.24.4

# Setup kubectl
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
kubectl get nodes

# install Calico Networking
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml

# print cluster join command
kubeadm token create --print-join-command

  2/ Use the printed join command on the worker nodes to add them to the
  cluster

  3/ Check installation
kubectl get nodes
